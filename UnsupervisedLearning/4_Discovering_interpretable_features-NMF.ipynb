{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF applied to Wikipedia articles\n",
    "\n",
    "Nonnegative matrix factorization (NMF) has become a widely used tool for the analysis of high dimensional data as it automatically extracts sparse and meaningful features from a set of nonnegative data vectors.\n",
    "\n",
    "NMF approximates a matrix X with a low-rank matrix approximation.\n",
    "\n",
    "The reason why NMF has become so popular is because of its ability to automatically extract sparse and easily interpretable factors.\n",
    "\n",
    "#### Image processing\n",
    "Say we take a gray-level image of a face containing p pixels, and squash the data into a single vector such that the ith entry represents the value of the ith pixel. Let the rows of \n",
    "\\begin{align}\n",
    " \\mathbf{X} \n",
    "\\in \\mathbb{R}^{p \\times n} \n",
    " \\end{align}\n",
    " represent the p pixels, and the n columns each represent one image.\n",
    " \n",
    " NMF will produce two matrices W and H. The columns of W can be interpreted as images (the basis images), and H tells us how to sum up the basis images in order to reconstruct an approximation to a given face.\n",
    " \n",
    " <img src=\"imagenmf.png\" >\n",
    " \n",
    "In the case of facial images, the basis images are features such as eyes, noses, moustaches, and lips, while the columns of H indicate which feature is present in which image.\n",
    "\n",
    "### Text mining\n",
    "In text mining consider the bag-of-words matrix representation where each row corresponds to a word, and each column to a document.\n",
    "\n",
    "NMF will produce two matrices W and H. The columns of W can be interpreted as basis documents (bags of words). What interpretation can we give to such a basis document in this case? They represent topics! Sets of words found simultaneously in different documents. H tells us how to sum contributions from different topics to reconstruct the word mix of a given original document.\n",
    "\n",
    "<img src=\"textnmf.png\">\n",
    "\n",
    "Therefore, given a set of documents, NMF identifies topics and simultaneously classifies the documents among these different topics.\n",
    "\n",
    "### Hyperspectral unmixing\n",
    "A hyperspectral image typically has 100 to 200 wavelength-indexed bands showing the fraction of incident light being reflected by the pixel at each of those wavelengths. Given such an image we want to identify the different materials present in it (e.g. grass, roads, metallic surfaces) â€“ these are called the endmembers. Then we want to know which endmembers are present in each pixel, and in what proportion. For example, a pixel might be reflecting 0.3 x the spectral signal of grass, and 0.7 x the spectral signal of a road surface.\n",
    "\n",
    "NMF will produce two matrices W and H. The columns of W can be interpreted as basis endmembers. H tells us how to sum contributions from different endmembers to reconstruct the spectral signal observed at a pixel.\n",
    "\n",
    "<img src=\"Hyperspectral.png\">\n",
    "\n",
    "Given a hyperspectral image, NMF is able to compute the spectral signatures of the endmembers, and simultaneously the abundance of each endmember in each pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "\n",
    "df = pd.read_csv('Wikipedia_articles/wikipedia-vectors.csv', index_col=0)\n",
    "articles = csr_matrix(df.transpose())\n",
    "titles = list(df.columns)\n",
    "\n",
    "# Create an NMF instance: model\n",
    "model = NMF(n_components=6)\n",
    "\n",
    "# Fit the model to articles\n",
    "model.fit(articles)\n",
    "\n",
    "# Transform the articles: nmf_features\n",
    "nmf_features = model.transform(articles)\n",
    "\n",
    "# Print the NMF features\n",
    "#print(nmf_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.003845\n",
      "1    0.000000\n",
      "2    0.000000\n",
      "3    0.575687\n",
      "4    0.000000\n",
      "5    0.000000\n",
      "Name: Anne Hathaway, dtype: float64\n",
      "0    0.000000\n",
      "1    0.005601\n",
      "2    0.000000\n",
      "3    0.422363\n",
      "4    0.000000\n",
      "5    0.000000\n",
      "Name: Denzel Washington, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create a pandas DataFrame: df\n",
    "df = pd.DataFrame(nmf_features,index=titles)\n",
    "\n",
    "# Print the row for 'Anne Hathaway'\n",
    "print(df.loc['Anne Hathaway'])\n",
    "\n",
    "# Print the row for 'Denzel Washington'\n",
    "print(df.loc['Denzel Washington'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine",
   "language": "python",
   "name": "machine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
